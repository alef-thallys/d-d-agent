import os
import re
import json
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from rich.console import Console
from rich.panel import Panel
from rich.theme import Theme

# --- CONFIGURA√á√ÉO ---
LIB_DIR = "./biblioteca"
OUTPUT_JSON = "rag_ready_manual.json"
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

# A P√°gina 11 do livro (In√≠cio Cap 1) √© a P√°gina 10 do arquivo PDF.
# Portanto, 11 + OFFSET = 10  =>  OFFSET = -1
PAGE_OFFSET = -1

# --- MAPA DE CAP√çTULOS (NOME -> P√ÅGINA INICIAL) ---
# O script vai ler da p√°gina X at√© o in√≠cio da pr√≥xima.
CHAPTER_MAP = {
    "Cap√≠tulo 1: Cria√ß√£o de Personagem": 11,   
    "Cap√≠tulo 2: Ra√ßas": 17,
    "Cap√≠tulo 3: Classes": 45,
    "Cap√≠tulo 4: Personalidade e Antecedentes": 121,
    "Cap√≠tulo 5: Equipamento": 143,
    "Cap√≠tulo 6: Op√ß√µes de Personaliza√ß√£o": 163,
    "Cap√≠tulo 7: Utilizando Habilidades": 173,
    "Cap√≠tulo 8: Aventurando-se": 181,
    "Cap√≠tulo 9: Combate": 189,
    "Cap√≠tulo 10: Conjura√ß√£o": 201,
    "Cap√≠tulo 11: Magias": 207,
    "Ap√™ndice A: Condi√ß√µes": 290,
    "FIM": 999  # Marcador para saber onde termina o √∫ltimo cap√≠tulo
}

console = Console(theme=Theme({"info": "cyan", "success": "bold green", "warning": "yellow"}))

# Regex apenas para Sub-se√ß√µes (ex: "AN√ÉO", "MAGIA", "COMBATE")
SECTION_PATTERN = re.compile(
    r"(?:^|\n)\s*([A-Z√É√Å√Ç√ä√â√ç√ï√ì√ö√á][A-Z√É√Å√Ç√ä√â√ç√ï√ì√ö√á\s\-:]{3,})(?:\n|$)"
)

def clean_text(text):
    # Remove cabe√ßalhos e n√∫meros de p√°gina soltos
    text = re.sub(r'LIVRO DO JOGADOR', '', text)
    text = re.sub(r'\n\s*\d+\s*\n', '\n', text) # Remove numera√ß√£o isolada
    text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text) # Corrige h√≠fens
    # Remove n√∫meros que aparecem sozinhos logo no in√≠cio do texto
    text = re.sub(r'^\s*\d+\s*\n', '', text) 
    return text

def process_pdf(file_path):
    console.print(Panel(f"üìò Lendo PDF: {os.path.basename(file_path)}", style="blue"))
    
    loader = PyPDFLoader(file_path)
    # Carrega todas as p√°ginas de uma vez (pode demorar um pouco se for gigante)
    all_pages = loader.load()
    total_pages_pdf = len(all_pages)
    
    rag_docs = []
    
    # Ordena os cap√≠tulos pela p√°gina para garantir a sequ√™ncia
    sorted_chapters = sorted(CHAPTER_MAP.items(), key=lambda x: x[1])

    for i in range(len(sorted_chapters) - 1):
        chapter_title, start_page = sorted_chapters[i]
        _, next_start_page = sorted_chapters[i+1]
        
        # Ajusta para √≠ndice do Python (0-based) e aplica Offset
        idx_start = max(0, start_page - 1 + PAGE_OFFSET)
        idx_end = min(total_pages_pdf, next_start_page - 1 + PAGE_OFFSET)

        if idx_start >= total_pages_pdf:
            console.print(f"[warning]‚ö†Ô∏è Cap√≠tulo '{chapter_title}' come√ßa na p√°g {start_page}, mas o PDF s√≥ tem {total_pages_pdf} p√°gs.[/warning]")
            continue

        # Extrai o texto desse intervalo de p√°ginas
        chapter_pages = all_pages[idx_start:idx_end]
        chapter_text = "\n".join([p.page_content for p in chapter_pages])
        chapter_text = clean_text(chapter_text)

        console.print(f"[info]üìñ Processando {chapter_title} (P√°gs {start_page}-{next_start_page-1})[/info]")

        # --- DIVIS√ÉO POR SE√á√ïES (IGUAL ANTES) ---
        sections = SECTION_PATTERN.split(chapter_text)
        current_section = "Geral"

        for j, segment in enumerate(sections):
            segment = segment.strip()
            if not segment: continue

            # Verifica se √© T√≠tulo de Se√ß√£o (Caixa Alta e curto)
            if j % 2 != 0 and len(segment) < 100:
                current_section = segment.title()
                continue
            
            # √â conte√∫do
            splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
            chunks = splitter.split_text(segment)
            
            for chunk in chunks:
                if len(chunk) < 50: continue
                rag_docs.append({
                    "content": chunk,
                    "metadata": {
                        "source": os.path.basename(file_path),
                        "chapter": chapter_title,
                        "section": current_section,
                        "page_range": f"{start_page}-{next_start_page-1}"
                    }
                })

    return rag_docs

def main():
    if not os.path.exists(LIB_DIR):
        console.print(f"[error]Pasta {LIB_DIR} n√£o existe![/error]")
        return

    pdf_files = [f for f in os.listdir(LIB_DIR) if f.lower().endswith(".pdf")]
    all_docs = []

    for pdf in pdf_files:
        docs = process_pdf(os.path.join(LIB_DIR, pdf))
        all_docs.extend(docs)

    with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
        json.dump(all_docs, f, ensure_ascii=False, indent=2)

    console.print(Panel(f"üíæ Sucesso! {len(all_docs)} chunks gerados manualmente.\nSalvo em: {OUTPUT_JSON}", style="bold green"))

if __name__ == "__main__":
    main()